{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.1 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.1/44.1 kB 546.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pqstv\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.0 MB 8.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/10.0 MB 9.8 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 9.0 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.0/10.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.5/10.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.1/10.0 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 4.1/10.0 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.6/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.7/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.2/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.8/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.0 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 447.5/447.5 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp311-none-win_amd64.whl (285 kB)\n",
      "   ---------------------------------------- 0.0/286.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.0/286.0 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.20.1-cp311-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.4 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.4 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 9.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.4 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 10.1 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.2 safetensors-0.4.5 tokenizers-0.20.1 transformers-4.46.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "          [ 0.2136, -1.6072,  0.5230,  1.4587],\n",
       "          [ 2.4053,  0.8354, -0.4058, -0.1202],\n",
       "          [ 1.2923,  1.0156, -1.4036, -1.1738],\n",
       "          [-0.9638, -0.4862, -2.7030, -1.1667],\n",
       "          [ 0.5169,  1.2041,  0.1021, -0.5893]]]),\n",
       " tensor([[[[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "           [ 0.0000, -0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000, -0.0000, -0.0000],\n",
       "           [ 0.0000,  0.0000, -0.0000, -0.0000],\n",
       "           [-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000, -0.0000]],\n",
       " \n",
       "          [[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "           [ 0.2136, -1.6072,  0.5230,  1.4587],\n",
       "           [ 0.0000,  0.0000, -0.0000, -0.0000],\n",
       "           [ 0.0000,  0.0000, -0.0000, -0.0000],\n",
       "           [-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000, -0.0000]],\n",
       " \n",
       "          [[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "           [ 0.2136, -1.6072,  0.5230,  1.4587],\n",
       "           [ 2.4053,  0.8354, -0.4058, -0.1202],\n",
       "           [ 0.0000,  0.0000, -0.0000, -0.0000],\n",
       "           [-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000, -0.0000]],\n",
       " \n",
       "          [[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "           [ 0.2136, -1.6072,  0.5230,  1.4587],\n",
       "           [ 2.4053,  0.8354, -0.4058, -0.1202],\n",
       "           [ 1.2923,  1.0156, -1.4036, -1.1738],\n",
       "           [-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000, -0.0000]],\n",
       " \n",
       "          [[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "           [ 0.2136, -1.6072,  0.5230,  1.4587],\n",
       "           [ 2.4053,  0.8354, -0.4058, -0.1202],\n",
       "           [ 1.2923,  1.0156, -1.4036, -1.1738],\n",
       "           [-0.9638, -0.4862, -2.7030, -1.1667],\n",
       "           [ 0.0000,  0.0000,  0.0000, -0.0000]],\n",
       " \n",
       "          [[-0.1165,  0.0403, -0.3077, -1.2563],\n",
       "           [ 0.2136, -1.6072,  0.5230,  1.4587],\n",
       "           [ 2.4053,  0.8354, -0.4058, -0.1202],\n",
       "           [ 1.2923,  1.0156, -1.4036, -1.1738],\n",
       "           [-0.9638, -0.4862, -2.7030, -1.1667],\n",
       "           [ 0.5169,  1.2041,  0.1021, -0.5893]]]]),\n",
       " tensor([[[[1, 0, 0, 0, 0, 0],\n",
       "           [1, 1, 0, 0, 0, 0],\n",
       "           [1, 1, 1, 0, 0, 0],\n",
       "           [1, 1, 1, 1, 0, 0],\n",
       "           [1, 1, 1, 1, 1, 0],\n",
       "           [1, 1, 1, 1, 1, 1]]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the mask tensor\n",
    "mask = torch.tensor(\n",
    "  [  \n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 1] \n",
    "  ])  # Shape: (1, 6, 6)\n",
    "\n",
    "# Define a sample input tensor for the decoder (batch_size=1, seq_len=6, vector_dim=4)\n",
    "input_tensor = torch.randn(1, 6, 4)\n",
    "\n",
    "# Applying the mask to the input tensor\n",
    "# Simulating the mask application by setting masked elements to zero based on the attention mask\n",
    "masked_output = input_tensor * mask.unsqueeze(-1)\n",
    "\n",
    "# Display the result\n",
    "input_tensor, masked_output, mask.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5451, -0.9219, -0.0328],\n",
      "        [-0.1412, -0.7991,  1.4858],\n",
      "        [ 0.0860,  0.3880,  0.3223]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# vocab 크기와 임베딩 차원 설정\n",
    "vocab_size = 10\n",
    "embedding_dim = 3\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# 단어 인덱스 0~9999까지 임베딩 가능\n",
    "input_indices = torch.tensor([0, 3, 8])\n",
    "output = embedding_layer(input_indices)\n",
    "print(output)  # 각 인덱스에 해당하는 512차원 임베딩 벡터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638d7a10c795467ab2729dd7100160c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pqstv\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pqstv\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51934bd24ea14e0aacbfe293ce4c326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb524975414a4e64922e545d7d9e4459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c3c4884d5c41f4a04639fe8ffac68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰: ['i', 'love', 'nl', '##p']\n",
      "인덱스: [1045, 2293, 17953, 2361]\n",
      "텐서: tensor([ 1045,  2293, 17953,  2361])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 예시 토크나이저 로드 (BERT 토크나이저)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 텍스트를 토큰화하고 텐서로 변환\n",
    "input_text = \"I love NLP\"\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "indices = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "# 직접 텐서로 변환\n",
    "tensor = torch.tensor(indices)\n",
    "print(\"토큰:\", tokens)\n",
    "print(\"인덱스:\", indices)\n",
    "print(\"텐서:\", tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
